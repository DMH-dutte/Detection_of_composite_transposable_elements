{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection of composite transposable elements \n",
    "## Notebook 2: Data Preparation\n",
    "## Description:\n",
    "Transposable elements are sequences in genomes that can change their position in the genome and that is also the reason why they are colloquially called “jumping genes”. They are able to affect the composition and size of genetic replicons. Our research interest in this project are composite transposable elements, which are flanked by two inverted repeats and transposable elements. Composite transposable elements are moving as one unit within a genome and are copying and inserting genes enclosed by itself. The following traits of composite transposable elements are making their detection challenging: \n",
    "\n",
    "1. Sometimes terminal information such as repeats or transposable elements are missing, which would define the boundaries of a composite transposable element.\n",
    "2. Composite transposable elements are diverse in their genetic composition and size. \n",
    "\n",
    "Composite transposable elements are usually associated with essential and indispensable genes, which are having a high gene frequency across genomes. We hypothesize that the genetic frequency landscape of a genetic element will follow a particular pattern, which can be used as a marker for putative regions of composite transposable elements. Thus, we are representing here an approach to detect regions of putative composite transposable elements using gene frequencies, protein family clusters and positions of composite transposable elements as input for a supervised LSTM-based neural network model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Repo \n",
    "* add own github link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants:\n",
    "Dustin Martin Hanke: dhanke@ifam.uni-kiel.de\n",
    "\n",
    "Wang Yiging: ywang@ifam.uni-kiel.de "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course and Semester\n",
    "Machine Learning with TensorFlow - Wintersemester 2021/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "If you are releasing the software under some certain license, you can mention it and also include the `LICENSE.md` file in the folder\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 1D input arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "arrays/2D_freq_mcl.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-af8b9d8d3db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Arrays have been stored as 1D-arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtwo_d_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays/2D_freq_mcl.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfrequencies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays/frequencies.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays/labels.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gxfs_work1/cau/sunam188/environments/tensorflow/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gxfs_work1/cau/sunam188/environments/tensorflow/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gxfs_work1/cau/sunam188/environments/tensorflow/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: arrays/2D_freq_mcl.csv not found."
     ]
    }
   ],
   "source": [
    "#Arrays have been stored as 1D-arrays\n",
    "two_d_data = np.loadtxt('arrays/2D_freq_mcl.csv', delimiter=',') \n",
    "frequencies = np.loadtxt('arrays/frequencies.csv', delimiter=',')\n",
    "labels = np.loadtxt('arrays/labels.csv', delimiter=',')\n",
    "\n",
    "#Bring 1D-arrays into the correct shape:\n",
    "two_d_data = two_d_data.reshape(807447, 25, 2)\n",
    "frequencies = frequencies.reshape(807447, 25)\n",
    "labels = labels.reshape(807447, 25)\n",
    "print(two_d_data.shape, frequencies.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the labels into binary labels:\n",
    "1. [1] -> is containing a comTE\n",
    "2. [0] -> doesn't contain a comTE\n",
    "\n",
    "We assumed that it would be worth it to start a binary classification approach to validate, if our approach of detecting composite transposable elements is valid at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_binary(array):\n",
    "    new_list = []\n",
    "    for element in array:\n",
    "        if np.sum(element) != 0:\n",
    "            new_list.append(1)\n",
    "        else:\n",
    "            new_list.append(0)\n",
    "    new_array = np.array(new_list).reshape(array.shape[0], 1)\n",
    "    return new_array\n",
    "\n",
    "binary_array = make_binary(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract randomly samples and labels from the data to maintain a 50/50 distribution of negative/positive samples:\n",
    "\n",
    "It has been observed that the labels are dramatically biased and it was decided to randomly choose negative samples from the dataset and to keep all positive samples that were available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_x = list()\n",
    "reduced_y = list()\n",
    "all_zeros = list()\n",
    "for i in range(len(two_d_data)):\n",
    "    if binary_array[i] == 1:\n",
    "        reduced_x.append(two_d_data[i])\n",
    "        reduced_y.append(binary_array[i])\n",
    "    else:\n",
    "        all_zeros.append(two_d_data[i])\n",
    "zero_x = list()\n",
    "\n",
    "for i in range(len(reduced_x)):\n",
    "    reduced_x.append(random.choice(all_zeros))\n",
    "    reduced_y.append(np.array([0]))\n",
    "\n",
    "    \n",
    "reduced_x = np.array(reduced_x)\n",
    "reduced_y = np.array(reduced_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting arrays containing at least 4 fragmentary comTE positions in a chunk.\n",
    "We decided to increase the signal strength of a chunk of the input data by creating an input dataset that contains at least 4 positions relating to a comTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "two_d_4 = []\n",
    "labels4 = []\n",
    "for i, el in enumerate(labels):\n",
    "    \n",
    "    if np.sum(el) >= 4:\n",
    "        if counter == 0:\n",
    "            labels4 = np.concatenate([np.array([1])])\n",
    "            two_d_4 = np.concatenate([two_d_data[i]])\n",
    "        else:\n",
    "            labels4 = np.concatenate([labels4, np.array([1])])\n",
    "            two_d_4 = np.concatenate([two_d_4, two_d_data[i]])\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "#labels4 = list(labels4)\n",
    "#two_d_4 = list(two_d_4)\n",
    "\n",
    "for i in range(len(labels4)):\n",
    "    two_d_4 = np.append(two_d_4, random.choice(all_zeros))\n",
    "    labels4 = np.append(labels4, np.array([0])) \n",
    "    \n",
    "labels4 = labels4.reshape(29360, 1)\n",
    "two_d_4 = two_d_4.reshape(29360, 25, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_flat_arrays(where, array, name):\n",
    "    '''\n",
    "    Saves flattened np arrays\n",
    "    '''\n",
    "    np.savetxt(\"{}/{}.csv\".format(where, name), array, delimiter=',')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_flat_arrays(\"arrays\", frequencies.flatten(), \"frequencies\")\n",
    "save_flat_arrays(\"arrays\", two_d_training.flatten(), \"2D_freq_mcl\")\n",
    "save_flat_arrays(\"arrays\", labels.flatten(), \"labels\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
